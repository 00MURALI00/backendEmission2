# -*- coding: utf-8 -*-
"""Framework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GIOiLYxliMgV9NBPzN7c8Pu0N754MYi1
"""
import sys
import io

if __name__ == "__main__":
    dataset = sys.argv[1]

import numpy as np
import pandas as pd

csv_data = io.StringIO(dataset)
data = pd.read_csv(csv_data)
data.columns = ["Model","Emissions (Kg)","MAPE","MSE","RMSE","MAE"]
data

data_new = {
    'Model': ['RNN', 'AR', 'ARIMA','LSTM', 'BI-LSTM', 'VARMA'],
    'Emissions (Kg)': ['0.000127', '0.000125', '0.000121', '0.000112', '0.000120', '0.000120'],
    'MAPE': ['0.20800', '7.70000', '4.25000', '4.53000', '3.19844', '459.26300'],
    'MSE': ['0.38619', '13.70000', '6.25000', '5.20000', '0.03730', '50.70000'],
    'RMSE': ['0.1817', '3.7000', '2.5000', '2.2000'	, '0.1930', '450.6500'],
    'MAE': ['0.571', '2.900', '4.700', '3.510', '0.040', '4.490']
}

"""***SAW Method***"""

criteria_columns = ["Emissions (Kg)","MAPE","MSE","RMSE","MAE"]

df_normalized_new = data.copy()
for column in criteria_columns:
    if column == 'Emissions (Kg)':
        df_normalized_new[column] = data[column].replace('[\$,]', '', regex=True).astype(float) / data[column].replace('[\$,]', '', regex=True).astype(float).max()
    else:
        df_normalized_new[column] = data[column].replace('[^\d.]', '', regex=True).astype(float) / data[column].replace('[^\d.]', '', regex=True).astype(float).max()
# print("\nNormalized Dataset:")
# print(df_normalized_new)

weights_saw = {'Emissions (Kg)': 0.2, 'MAPE': 0.2, 'MSE': 0.2, 'RMSE': 0.2,'MAE': 0.2}

df_normalized_new['SAW_Score'] = df_normalized_new[criteria_columns].dot(pd.Series(weights_saw))
df_ranked_saw = df_normalized_new.sort_values(by='SAW_Score', ascending=False).reset_index(drop=True)
# print("\nRanked Dataset (SAW):")
# print(df_ranked_saw[['Model', 'SAW_Score']])
import json

ranked_json = df_ranked_saw[['Model', 'SAW_Score']].set_index('Model').to_dict()['SAW_Score']
print(json.dumps(ranked_json))

"""***WP Method***"""

weights_wp = {'Emissions (Kg)': 0.2, 'MAPE': 0.2, 'MSE': 0.2, 'RMSE': 0.2,'MAE': 0.2}

df_normalized_new['WP_Score'] = (df_normalized_new[criteria_columns] ** list(weights_wp.values())).prod(axis=1) ** (1/len(weights_wp))
df_ranked_wp = df_normalized_new.sort_values(by='WP_Score', ascending=False).reset_index(drop=True)
# print("\nRanked Dataset (WP):")
# print(df_ranked_wp[['Model', 'WP_Score']])

""" ***TOPSIS Method***"""

from scipy.spatial.distance import euclidean



weights_topsis = {'Emissions (Kg)': 0.2, 'MAPE': 0.2, 'MSE': 0.2, 'RMSE': 0.2,'MAE': 0.2}

ideal_solution = df_normalized_new.max()
anti_ideal_solution = df_normalized_new.min()

df_normalized_new['DistanceToIdeal'] = df_normalized_new[criteria_columns].apply(lambda row: euclidean(row, ideal_solution[criteria_columns]), axis=1)
df_normalized_new['DistanceToAntiIdeal'] = df_normalized_new[criteria_columns].apply(lambda row: euclidean(row, anti_ideal_solution[criteria_columns]), axis=1)
df_normalized_new['TOPSIS_Score'] = df_normalized_new['DistanceToAntiIdeal'] / (df_normalized_new['DistanceToIdeal'] + df_normalized_new['DistanceToAntiIdeal'])
df_ranked_topsis = df_normalized_new.sort_values(by='TOPSIS_Score', ascending=False).reset_index(drop=True)

# print("\nRanked Dataset (TOPSIS):")
# print(df_ranked_topsis[['Model', 'TOPSIS_Score']])

"""***AHP Method***"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

data_new = {
    'Model': ['RNN', 'AR', 'ARIMA','LSTM', 'BI-LSTM', 'VARMA'],
    'Emissions (Kg)': ['0.000127', '0.000125', '0.000121', '0.000112', '0.000120', '0.000120'],
    'MAPE': ['0.20800', '7.70000', '4.25000', '4.53000', '3.19844', '459.26300'],
    'MSE': ['0.38619', '13.70000', '6.25000', '5.20000', '0.03730', '50.70000'],
    'RMSE': ['0.1817', '3.7000', '2.5000', '2.2000'	, '0.1930', '450.6500'],
    'MAE': ['0.571', '2.900', '4.700', '3.510', '0.040', '4.490']
}

df_new = pd.DataFrame(data_new)

df_new['Emissions (Kg)'] = pd.to_numeric(df_new['Emissions (Kg)'].replace('[\$,]', '', regex=True), errors='coerce')
df_new['MAPE'] = pd.to_numeric(df_new['MAPE'].replace('[^\d.]', '', regex=True), errors='coerce')
df_new['MSE'] = pd.to_numeric(df_new['MSE'].replace('[^\d.]', '', regex=True), errors='coerce')
df_new['RMSE'] = pd.to_numeric(df_new['RMSE'].replace('[^\d.]', '', regex=True), errors='coerce')
df_new['MAE'] = pd.to_numeric(df_new['MAE'].replace('[^\d.]', '', regex=True), errors='coerce')

criteria_columns = ["Emissions (Kg)","MAPE","MSE","RMSE","MAE"]
criteria_comparison_matrix = pd.DataFrame(index=criteria_columns, columns=criteria_columns, dtype=float)

criteria_comparison_matrix.loc['Emissions (Kg)'] = [1, 0.5, 0.3, 0.8, 0.7]
criteria_comparison_matrix.loc['MAPE'] = [2, 1, 0.5, 1.5, 1.2]
criteria_comparison_matrix.loc['MSE'] = [3, 2, 1, 2, 1.5]
criteria_comparison_matrix.loc['RMSE'] = [1/0.8, 1/1.5, 1/2, 1, 0.8]
criteria_comparison_matrix.loc['MAE'] = [1/0.7, 1/1.2, 1/1.5, 1/0.8, 1]

criteria_comparison_matrix /= criteria_comparison_matrix.sum(axis=1)

criteria_weights = criteria_comparison_matrix.mean(axis=1)

df_normalized_ahp = df_new.copy()
for column in criteria_columns:
    df_normalized_ahp[column] = df_new[column] / df_new[column].max()

df_normalized_ahp['AHP_Score'] = df_normalized_ahp[criteria_columns].dot(criteria_weights)

df_ranked_ahp = df_normalized_ahp.sort_values(by='AHP_Score', ascending=False).reset_index(drop=True)

# print("\nRanked Dataset (AHP):")
# print(df_ranked_ahp[['Model', 'AHP_Score']])